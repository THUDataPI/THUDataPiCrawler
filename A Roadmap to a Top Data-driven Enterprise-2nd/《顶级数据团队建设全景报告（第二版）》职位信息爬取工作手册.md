
# 《顶级数据团队建设全景报告（第二版）》职位信息爬取工作手册

## 一、目标

《顶级数据团队建设全景报告（第二版）》职位信息数据爬取。从国内外主要招聘网站提取尽可能多的与数据相关的职位的信息，分析当下企业对数据相关职位的需求和该职位的发展前景。

## 二、目标网站

[拉勾](https://www.lagou.com/)、[boss 直聘](https://www.zhipin.com/)、[猎聘](https://www.liepin.com/)、[智联招聘](https://www.zhaopin.com/)、[中华英才网](http://www.chinahr.com/beijing/)、[前程无忧](http://www.51job.com/)、[58 同城招聘](http://www.58.com/zhaopin/)、[赶集网招聘](http://www.ganji.com/zhaopin/)。

## 三、职位信息搜索关键词

待定。

## 四、职位信息数据存储格式说明
			
| 字段名称 | 存储样例-猎聘网 | 存储样例-中华英才网 | 存储样例-前程无忧 | 注意事项 |
|-------|--------|--------|-------|--------|
| 职位名称 | 数据分析 | 数据分析岗 | 大数据平台可视化开发岗 | |
| 职位分类标签 | NULL | NULL | NULL |	|
| 部门 | COO办 | NULL | NULL |	|
| 工作地点 | 广州-越秀区 | 深圳-南山区 | 济南-NULL |	|
| 工作性质 | NULL | 全职 | NULL |	|
| 经验要求 | 1年经验以上 | 2年经验 | 1年经验 | “应届生”、“无经验要求”全部改成“0年经验” |
| 学历要求 | 本科及以上 | 大专 | 本科 | |
| 薪资 | 5000-7000 | 10000-15000 | 6000-15000 | 元/月薪 |
| 专业要求 | 不限 | NULL | NULL |	|
| 招聘人数 | NULL | NULL | 3 | “若干人”统一标注 -1；“不限人数”标注-2 |
| 职位诱惑 | 发展空间大, 五险一金, 上市公司 | 绩效奖金, 节日福利, 优秀人才多, 领导易相处, 项目奖金, 帅哥美女多, 员工培训, 年终奖, 员工旅游, 晋升空间大, 五险一金, 带薪年假 | 五险一金, 弹性工作, 年终奖金 | 逗号分隔 |
| 岗位介绍 | 工作职责：1、数据汇总及分析 2、项目跟进、沟通协调 3、协助制定及优化工作相关制度及流程 4、处理办公室日常行政事务。任职资格：1、熟练运用excel进行数据处理分析；2、文字和语言的组织能力强；3、逻辑能力强4、沟通、协调、应变能力佳；', '5、有独立解决问题的兴趣和能力，崇尚团队协作；', '6、有统计或财务背景为佳'。 | 岗位职责：1、深入理解公司业务需求，搭建公司大数据风控体系和平台； 2、参与风险管理部基于客户、商户基本信息、交易信息的数据分析和数据挖掘模型的研究，协助提升风控系统风险识别准确性；3、对风控数据进行统计分析，发现数据中的相关关系，为风控模型创建并筛选变量，为风险政策的优化提供数据支撑；4、对风控数据进行挖掘，利用统计分析、决策树、回归算法、机器学习或时间序列等技术建立信用风险预测模；5、分析统计并发送逾期报表、业务报表等风险管理部日常报表；6、对接财务完成对催收部门绩效统计及考核；| 岗位要求：1、本科及以上学历，统计学、数学等相关专业；2、一年以上数据分析相关工作经验；3、熟练使用SQL、Excel、SAS或其他分析软件；4、工作严谨认真，有一定的抗压能力。	岗位职责：负责基于大数据平台可视化展示和应用开发。任职要求： 一年以上工作经验，熟悉javascript、java等语言，熟悉web应用开发，熟悉biee或百度ECHARTS等的开发优先。职能类别：软件工程师 |	直接存储 |
| 公司名称 | 太平洋网络 | 深圳超富资产管理有限公司 | 山东全息信息科技有限公司 | |
| 公司行业 | 互联网,移动互联网,电子商务 | 证券 | 计算机软件,互联网,电子商务 | 逗号分隔 | 
| 公司性质 | 国内上市公司 | 民营，私企 | 民营公司 | |
| 融资阶段 | 已上市 | NULL | NULL | |
| 公司规模 | 1000-2000人 | 101－300人 | 50-150人 | 格式统一为：50-100人 这种格式，不要有其他汉字 |
| 公司主页 | NULL | NULL | NULL | |
| 发布日期 | 2017/3/24 | 2017/2/28 | 2017/3/21 | 日期形式一定统一成“年/月/日”格式 |
| 发布网站 | 猎聘网 | 中华英才网 | 前程无忧 | | 
| 原始 URL | https://www.liepin.com/job/197985732.shtml |http://www.chinahr.com/job/5485227593433605.html | http://jobs.51job.com/jinan/80274449.html | 网站URL只保留最简洁的形式 |

> **说明：**
> 1.  各字段存储顺序请按照格式说明中的顺序存储。可以选择数据库存储，也可以直接采用 CSV 格式存储。
> 2. 进行职位过滤，仅爬取需要的职位信息。
> 3. 爬取网站中如果没有相应字段信息，则此字段填入“NULL”。
> 4. 爬取时注意数据的全面性。数据不应该只局限在北上广深等城市，数据覆盖面尽可能广泛。

## 五、任务分配及进度安排
待定

## 六、职位信息数据汇总格式

职位信息数据以 EXCEL 文件提交，文件统一命名成 “THUDataPiCrawler_来源网站域名_数据月份” 的形式，例如：`THUDataPiCrawler_chinahr_2017_03.csv`，代表从中华英才网（chinahr）爬取的 2017 年 3 月发布的相关职位信息。职位信息数据汇总样例参见 [THUDataPiCrawler_chinahr_2017_03.csv](https://github.com/THUDataPI/THUDataPiCrawler/blob/master/A%20Roadmap%20to%20a%20Top%20Data-driven%20Enterprise-2nd/Sample/THUDataPiCrawler_chinahr_2017_03.csv)。

## 七、爬虫源代码汇总方式

爬虫源代码统一提交至 THU 数据派在 GitHub 的社区中。在目录`THUDataPI/THUDataPiCrawler/A Roadmap to a Top Data-driven Enterprise-2nd/` 中新建文件夹目录，文件夹目录以 “THUDataPiCrawler_来源网站域名” 的形式命名，例如：`THUDataPiCrawler_chinahr`，代表针对中华英才网的爬虫源代码。

## 附录：爬虫相关资料整理

### 互联网学习资料

[Scrapy 官方网站](https://scrapy.org/)
[Scrapy 官方教程](https://doc.scrapy.org/en/latest/intro/tutorial.html)
[Scrapy 入门教程](http://scrapy-chs.readthedocs.io/zh_CN/0.24/intro/tutorial.html)
[极客学院 Scrapy 中文指南](http://wiki.jikexueyuan.com/project/scrapy/)
[Python爬虫(六)--Scrapy框架学习](http://www.jianshu.com/p/078ad2067419)
[定向爬虫：Scrapy 初探](http://www.jikexueyuan.com/course/1287.html)

### THU 数据派爬虫资料

《顶级数据团队建设全景报告（第一版）》职位信息爬取源代码存放在 [THUDataPiCrawler(old version)](https://github.com/THUDataPI/THUDataPiCrawler-old-version) 中。主要包括针对拉勾网、前程无忧等网站，对有关于 “大数据”、“数据分析” 等关键词的职位信息的爬取代码。
